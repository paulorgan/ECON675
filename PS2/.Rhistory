}
M <- 100
# define blank vectors to fill with simulated results and optimal Ks
# (not matrices now, since we are using optimal K)
thetas <- rep(NA, M)
SEs    <- rep(NA, M)
Ks     <- rep(NA, M)
# simulate M times
set.seed(22)
ptm <- proc.time()
for(m in 1:M){
# draw data
data <- dgp(n)
X   <- data$X
Y   <- data$Y
Tee <- data$Tee
# given data, estimate optimal K using cross validation
K_CV <- crossval(X, Y, Tee, nK, K)
# generate basis, add intercept
X_poly <- cbind(1,polybasis(X,K[K_CV]))
# define M_P (I-P(P'P)^{-1}P)
M_P <- diag(n) - (X_poly %*% solve((t(X_poly) %*% X_poly)) %*% t(X_poly))
# estimate theta(K)
theta <- (t(Tee) %*% M_P %*% Y)/(t(Tee) %*% M_P %*% Tee)
# sigma (for variance estimate)
sigma <- diag( as.numeric((M_P %*% (Y - Tee*as.numeric(theta))))^2 )
# standard error
bread <- solve((t(Tee) %*% M_P %*% Tee))
se <- sqrt( bread %*% (t(Tee)%*%M_P%*%sigma%*%M_P%*%Tee) %*% bread)
# save to vectors
thetas[m] <- theta
SEs[m]    <- se
Ks[m]     <- K_CV
}
proc.time() - ptm
summary(Ks)
crossval <- function(X, Y, Tee, nK, K){
# blank vector to fill with MSE
MSEs <- rep(NA, nK)
# loop through each K to identify optimal bandwidth
for(k in 1:nK){
# define polynomial basis
X_poly <- cbind(1, Tee, polybasis(X, K[k]))
# QR decomposition
X_poly_Q <- qr.Q(qr(X_poly))
XX <- X_poly_Q %*% t(X_poly_Q)
Y_hat <- XX %*% Y
W <- diag(XX)
MSEs[k] <- mean( ((Y-Y_hat)/(1-W))^2 )
}
# return the optimal K
return(K[which.min(MSEs)])
}
M <- 10
# define blank vectors to fill with simulated results and optimal Ks
# (not matrices now, since we are using optimal K)
thetas <- rep(NA, M)
SEs    <- rep(NA, M)
Ks     <- rep(NA, M)
# simulate M times
set.seed(22)
ptm <- proc.time()
for(m in 1:M){
# draw data
data <- dgp(n)
X   <- data$X
Y   <- data$Y
Tee <- data$Tee
# given data, estimate optimal K using cross validation
K_CV <- crossval(X, Y, Tee, nK, K)
# generate basis, add intercept
X_poly <- cbind(1,polybasis(X,K[K_CV]))
# define M_P (I-P(P'P)^{-1}P)
M_P <- diag(n) - (X_poly %*% solve((t(X_poly) %*% X_poly)) %*% t(X_poly))
# estimate theta(K)
theta <- (t(Tee) %*% M_P %*% Y)/(t(Tee) %*% M_P %*% Tee)
# sigma (for variance estimate)
sigma <- diag( as.numeric((M_P %*% (Y - Tee*as.numeric(theta))))^2 )
# standard error
bread <- solve((t(Tee) %*% M_P %*% Tee))
se <- sqrt( bread %*% (t(Tee)%*%M_P%*%sigma%*%M_P%*%Tee) %*% bread)
# save to vectors
thetas[m] <- theta
SEs[m]    <- se
Ks[m]     <- K_CV
}
proc.time() - ptm
?which.min
# blank vector to fill with MSE
MSEs <- rep(NA, nK)
for(k in 1:nK){
# define polynomial basis
X_poly <- cbind(1, Tee, polybasis(X, K[k]))
# QR decomposition
X_poly_Q <- qr.Q(qr(X_poly))
XX <- X_poly_Q %*% t(X_poly_Q)
Y_hat <- XX %*% Y
W <- diag(XX)
MSEs[k] <- mean( ((Y-Y_hat)/(1-W))^2 )
}
MSEs
K[which.min(MSEs)]
crossval <- function(X, Y, Tee, nK, K){
# blank vector to fill with MSE
MSEs <- rep(NA, nK)
# loop through each K to identify optimal bandwidth
for(k in 1:nK){
# define polynomial basis
X_poly <- cbind(1, Tee, polybasis(X, K[k]))
# QR decomposition
X_poly_Q <- qr.Q(qr(X_poly))
XX <- X_poly_Q %*% t(X_poly_Q)
Y_hat <- XX %*% Y
W <- diag(XX)
MSEs[k] <- mean( ((Y-Y_hat)/(1-W))^2 )
}
# return the optimal K
return(K[which.min(MSEs)])
}
K_CV <- crossval(X, Y, Tee, nK, K)
M <- 10
# define blank vectors to fill with simulated results and optimal Ks
# (not matrices now, since we are using optimal K)
thetas <- rep(NA, M)
SEs    <- rep(NA, M)
Ks     <- rep(NA, M)
# simulate M times
set.seed(22)
ptm <- proc.time()
for(m in 1:M){
# draw data
data <- dgp(n)
X   <- data$X
Y   <- data$Y
Tee <- data$Tee
# given data, estimate optimal K using cross validation
K_CV <- crossval(X, Y, Tee, nK, K)
# generate basis, add intercept
X_poly <- cbind(1,polybasis(X,K_CV))
# define M_P (I-P(P'P)^{-1}P)
M_P <- diag(n) - (X_poly %*% solve((t(X_poly) %*% X_poly)) %*% t(X_poly))
# estimate theta(K)
theta <- (t(Tee) %*% M_P %*% Y)/(t(Tee) %*% M_P %*% Tee)
# sigma (for variance estimate)
sigma <- diag( as.numeric((M_P %*% (Y - Tee*as.numeric(theta))))^2 )
# standard error
bread <- solve((t(Tee) %*% M_P %*% Tee))
se <- sqrt( bread %*% (t(Tee)%*%M_P%*%sigma%*%M_P%*%Tee) %*% bread)
# save to vectors
thetas[m] <- theta
SEs[m]    <- se
Ks[m]     <- K_CV
}
proc.time() - ptm
# plot to show results
# panel 1: histogram of optimal Ks
p1 <- ggplot(Ks) + geom_histogram()
# plot to show results
df <- data.frame(K = Ks, theta = thetas, se = SEs)
View(df)
# plot to show results
df <- data.frame(K = Ks, theta = thetas, se = SEs) %>%
mutate(ci_low = theta - 1.96*se,
ci_high = theta + 1.96*se)
# plot to show results
df <- data.frame(K = Ks, theta = thetas, se = SEs) %>%
mutate(ci_low = theta - 1.96*se,
ci_high = theta + 1.96*se) %>%
sort(ci_low)
# plot to show results
df <- data.frame(K = Ks, theta = thetas, se = SEs) %>%
mutate(ci_low = theta - 1.96*se,
ci_high = theta + 1.96*se)
View(df)
# plot to show results
df <- data.frame(K = Ks, theta = thetas, se = SEs) %>%
mutate(ci_low = theta - 1.96*se, ci_high = theta + 1.96*se) %>%
arrange(ci_low)
# panel 1: histogram of optimal Ks
p1 <- ggplot(df, aes(x=Ks)) + geom_histogram()
p1
# panel 1: histogram of optimal Ks
p1 <- ggplot(df, aes(x=Ks)) + geom_bar()
p1
install.packages()
install.packages('scales')
# panel 1: histogram of optimal Ks
p1 <- ggplot(df, aes(x=K)) + geom_bar()
p1
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + heom_histogram()
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + geom_histogram()
p2
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + geom_histogram(bins = 10)
p2
# panel 1: histogram of optimal Ks
p1 <- ggplot(df, aes(x=K)) + geom_bar()
p1
# panel 3: distribution of SEs
p3 <- ggplot(df, aes(x=se)) + geom_histogram(bins=12)
p3
# panel 4: confidence intervals, sorted by lower point
p4 <- ggplot(df) + geom_line(aes(x = 1:1000, y=ci_low))
p4
# plot to show results
df <- data.frame(K = Ks, theta = thetas, se = SEs, rep = 1:1000) %>%
mutate(ci_low = theta - 1.96*se, ci_high = theta + 1.96*se) %>%
arrange(ci_low)
View(df)
# plot to show results
df <- data.frame(K = Ks, theta = thetas, se = SEs, rep = 1:M) %>%
mutate(ci_low = theta - 1.96*se, ci_high = theta + 1.96*se) %>%
arrange(ci_low)
View(df)
# plot to show results
df <- data.frame(K = Ks, theta = thetas, se = SEs, rep = 1:M) %>%
mutate(ci_low = theta - 1.96*se, ci_high = theta + 1.96*se) %>%
arrange(ci_low) %>% mutate(rep_sorted = 1:M)
View(df)
# panel 4: confidence intervals, sorted by lower point
p4 <- ggplot(df) + geom_line(aes(x = rep_sorted, y=ci_low))
p4
# panel 4: confidence intervals, sorted by lower point
p4 <- ggplot(df) +
geom_line(aes(x = rep_sorted, y=ci_low)) +
geom_line(aes(x = rep_sorted, y=ci_high))
p4
gc()
n <- 500
# replications
M <- 1000
# define data generating process
dgp <- function(n){
# input:  sample size n
# output: n draws of X and Y according to DGPs as specified in PSet
# X is a d(5) by n matrix ~ U(-1,1)
X <- matrix(runif(n*5,-1,1), ncol=5)
# V ~ N(0,1) and U ~ N(0,1)
V <- rnorm(n)
U <- rnorm(n)
# Eps = .36...*(1+||X||^2)*V
E <- 0.3637899*(1+diag(X %*% t(X)))*V
# g_0(X) = exp(||X||^2)
G <- exp(diag(X %*% t(X)))
# T = ind(||x||+u >= 0) (times 1 to convert from Boolean to numeric)
Tee <- matrix((sqrt(diag(X %*% t(X))) + U >= 0)*1, ncol = 1)
# Y as defined in problem (assuming \theta_0 = 1)
Y <- matrix(Tee + G + E, ncol = 1)
# returning list with matrix X, vector Y, vector T
out = list(X=X,Y=Y,Tee=Tee)
}
# define polynomial basis
K <- c(6,11,21,26,56,61,126,131,252,257,262,267,272,277)
polybasis <- function(X,K){
# inputs: data matrix X, 'order' K
# outputs: polynomial basis of 'order' K
# Note: this gets really ugly at the end,
# but I was tired and gave up trying to find a more elegant way
if(K==6){basis <- poly(X,degree=1,raw=T)}
if(K==11){basis <- cbind(poly(X,degree=1,raw=T),
X[,1]^2,X[,2]^2,X[,3]^2,X[,4]^2,X[,5]^2)}
if(K==21){basis <- poly(X,degree=2,raw=T)}
if(K==26){basis <- cbind(poly(X,degree=2,raw=T),
X[,1]^3,X[,2]^3,X[,3]^3,X[,4]^3,X[,5]^3)}
if(K==56){basis <- poly(X,degree=3,raw=T)}
if(K==61){basis <- cbind(poly(X,degree=3,raw=T),
X[,1]^4,X[,2]^4,X[,3]^4,X[,4]^4,X[,5]^4)}
if(K==126){basis <- poly(X,degree=4,raw=T)}
if(K==131){basis <- cbind(poly(X,degree=4,raw=T),
X[,1]^5,X[,2]^5,X[,3]^5,X[,4]^5,X[,5]^5)}
if(K==252){basis <- poly(X,degree=5,raw=T)}
if(K==257){basis <- cbind(poly(X,degree=5,raw=T),
X[,1]^6,X[,2]^6,X[,3]^6,X[,4]^6,X[,5]^6)}
if(K==262){basis <- cbind(poly(X,degree=5,raw=T),
X[,1]^6,X[,2]^6,X[,3]^6,X[,4]^6,X[,5]^6,
X[,1]^7,X[,2]^7,X[,3]^7,X[,4]^7,X[,5]^7)}
if(K==267){basis <- cbind(poly(X,degree=5,raw=T),
X[,1]^6,X[,2]^6,X[,3]^6,X[,4]^6,X[,5]^6,
X[,1]^7,X[,2]^7,X[,3]^7,X[,4]^7,X[,5]^7,
X[,1]^8,X[,2]^8,X[,3]^8,X[,4]^8,X[,5]^8)}
if(K==272){basis <- cbind(poly(X,degree=5,raw=T),
X[,1]^6,X[,2]^6,X[,3]^6,X[,4]^6,X[,5]^6,
X[,1]^7,X[,2]^7,X[,3]^7,X[,4]^7,X[,5]^7,
X[,1]^8,X[,2]^8,X[,3]^8,X[,4]^8,X[,5]^8,
X[,1]^9,X[,2]^9,X[,3]^9,X[,4]^9,X[,5]^9)}
if(K==277){basis <- cbind(poly(X,degree=5,raw=T),
X[,1]^6,X[,2]^6,X[,3]^6,X[,4]^6,X[,5]^6,
X[,1]^7,X[,2]^7,X[,3]^7,X[,4]^7,X[,5]^7,
X[,1]^8,X[,2]^8,X[,3]^8,X[,4]^8,X[,5]^8,
X[,1]^9,X[,2]^9,X[,3]^9,X[,4]^9,X[,5]^9,
X[,1]^10,X[,2]^10,X[,3]^10,X[,4]^10,X[,5]^10)}
return(basis)
}
# number of different orders to test
nK <- length(K)
crossval <- function(X, Y, Tee, nK, K){
# blank vector to fill with MSE
MSEs <- rep(NA, nK)
# loop through each K to identify optimal bandwidth
for(k in 1:nK){
# define polynomial basis
X_poly <- cbind(1, Tee, polybasis(X, K[k]))
# QR decomposition
X_poly_Q <- qr.Q(qr(X_poly))
XX <- X_poly_Q %*% t(X_poly_Q)
Y_hat <- XX %*% Y
W <- diag(XX)
MSEs[k] <- mean( ((Y-Y_hat)/(1-W))^2 )
}
# return the optimal K
return(K[which.min(MSEs)])
}
thetas <- rep(NA, M)
SEs    <- rep(NA, M)
Ks     <- rep(NA, M)
set.seed(22)
ptm <- proc.time()
for(m in 1:M){
# draw data
data <- dgp(n)
X   <- data$X
Y   <- data$Y
Tee <- data$Tee
# given data, estimate optimal K using cross validation
K_CV <- crossval(X, Y, Tee, nK, K)
# generate basis, add intercept
X_poly <- cbind(1,polybasis(X,K_CV))
# define M_P (I-P(P'P)^{-1}P)
M_P <- diag(n) - (X_poly %*% solve((t(X_poly) %*% X_poly)) %*% t(X_poly))
# estimate theta(K)
theta <- (t(Tee) %*% M_P %*% Y)/(t(Tee) %*% M_P %*% Tee)
# sigma (for variance estimate)
sigma <- diag( as.numeric((M_P %*% (Y - Tee*as.numeric(theta))))^2 )
# standard error
bread <- solve((t(Tee) %*% M_P %*% Tee))
se <- sqrt( bread %*% (t(Tee)%*%M_P%*%sigma%*%M_P%*%Tee) %*% bread)
# save to vectors
thetas[m] <- theta
SEs[m]    <- se
Ks[m]     <- K_CV
}
proc.time() - ptm
862/60
df <- data.frame(K = Ks, theta = thetas, se = SEs, rep = 1:M) %>%
mutate(ci_low = theta - 1.96*se, ci_high = theta + 1.96*se) %>%
arrange(ci_low) %>% mutate(rep_sorted = 1:M)
# panel 1: histogram of optimal Ks
p1 <- ggplot(df, aes(x=K)) + geom_bar()
p1
# panel 1: histogram of optimal Ks
k_df <- df %>% group_by(K) %>% summarise(Count = n()) %>% mutate(K = as.character(K))
View(k_df)
p1 <- ggplot(k_df, aes(x=K,y=Count)) + geom_bar()
p1
p1 <- ggplot(df, aes(x=K)) + geom_bar()
p1
# panel 1: histogram of optimal Ks
k_df <- df %>% group_by(K) %>% summarise(Count = n()) %>% mutate(K = as.character(K))
p1 <- ggplot(k_df, aes(x=K,y=Count)) + geom_bar(stat='identity')
p1
p1 <- ggplot(k_df, aes(x=K,y=Count)) + geom_bar(stat='identity') +
theme_minimal()
p1
p1 <- ggplot(k_df, aes(x=K,y=Count)) + geom_bar(stat='identity') +
theme_few()
require(ggthemes)
p1 <- ggplot(k_df, aes(x=K,y=Count)) + geom_bar(stat='identity') +
theme_few()
p1
p1 <- ggplot(k_df, aes(x=K,y=Count)) + geom_bar(stat='identity') +
theme_minimal()
p1
p1 <- ggplot(k_df, aes(x=K,y=Count)) + geom_bar(stat='identity') +
theme_minimal() + ggtitle('Optimal K')
p1
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + geom_histogram(bins=12)
p2
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + geom_histogram(bins=12) +  theme_minimal() +
labs(title='Estimates of Theta',x='Theta',y='Count')
p2
# panel 3: distribution of SEs
p3 <- ggplot(df, aes(x=se)) + geom_histogram(bins=12) + theme_minimal() +
labs(title='SEs on Estimates of Theta',x='Standard Error',y='Count')
p3
# panel 4: confidence intervals, sorted by lower point
p4 <- ggplot(df) +
geom_line(aes(x = rep_sorted, y=ci_low)) +
geom_line(aes(x = rep_sorted, y=ci_high)) +
theme_minimal() +
labs(title='Confidence Intervals for Theta',x='Replication (Sorted)',y='Theta')
p4
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + geom_histogram(bins=12) + theme_minimal() +
geom_vline(1,'dashed','red',2) +
labs(title='Estimates of Theta',x='Theta',y='Count')
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + geom_histogram(bins=12) + theme_minimal() +
geom_vline(xintercept=1,'dashed','red',2) +
labs(title='Estimates of Theta',x='Theta',y='Count')
p2
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + geom_histogram(bins=12) + theme_minimal() +
geom_vline(xintercept=1,linetype='dashed',color='red',size=10) +
labs(title='Estimates of Theta',x='Theta',y='Count')
p2
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + geom_histogram(bins=12) + theme_minimal() +
geom_vline(xintercept=1,linetype='dotted',color='red',size=5) +
labs(title='Estimates of Theta',x='Theta',y='Count')
p2
# panel 2: distribution of theta
p2 <- ggplot(df, aes(x=theta)) + geom_histogram(bins=12) + theme_minimal() +
geom_vline(xintercept=1,linetype='solid',color='red',size=2) +
labs(title='Estimates of Theta',x='Theta',y='Count')
p2
# panel 4: confidence intervals, sorted by lower point
p4 <- ggplot(df) +
geom_line(aes(x = rep_sorted, y=ci_low)) +
geom_line(aes(x = rep_sorted, y=ci_high)) +
geom_hline(yintercept=1,linetype='solid',color='red',size=2) +
theme_minimal() +
labs(title='Confidence Intervals for Theta',x='Replication (Sorted)',y='Theta')
p4
# panel 4: confidence intervals, sorted by lower point
p4 <- ggplot(df) +
geom_line(aes(x = rep_sorted, y=ci_low)) +
geom_line(aes(x = rep_sorted, y=ci_high)) +
geom_hline(yintercept=1,linetype='solid',color='red',size=1) +
theme_minimal() +
labs(title='Confidence Intervals for Theta',x='Replication (Sorted)',y='Theta')
p4
# panel 4: confidence intervals, sorted by lower point
p4 <- ggplot(df) +
geom_line(aes(x = rep_sorted, y=ci_low)) +
geom_line(aes(x = rep_sorted, y=ci_high)) +
geom_hline(yintercept=1,linetype='solid',color='red',size=1) +
theme_tufte() +
labs(title='Confidence Intervals for Theta',x='Replication (Sorted)',y='Theta')
p4
# combine with multiplot
multiplot(p1, p2, p3, p4, cols=2)
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
# combine with multiplot
multiplot(p1, p2, p3, p4, cols=2)
# combine with multiplot
source('multiplot.R')
plot <- multiplot(p1, p2, p3, p4, cols=2)
# save
ggsave('q3_4c.png')
png('q3_4c_R.png')
multiplot(p1, p2, p3, p4, cols=2)
dev.off()
p4 <- ggplot(df) +
geom_line(aes(x = rep_sorted, y=ci_low)) +
geom_line(aes(x = rep_sorted, y=ci_high)) +
geom_hline(yintercept=1,linetype='solid',color='red',size=1) +
theme_minimal() +
labs(title='Confidence Intervals for Theta',x='Replication (Sorted)',y='Theta')
p4
source('multiplot.R')
png('q3_4c_R.png')
multiplot(p1, p2, p3, p4, cols=2)
dev.off()
?png
png('q3_4c_R.png', width=6.5, units = 'in')
png('q3_4c_R.png', width=5, height = 5, units = 'in')
p2 <- ggplot(df, aes(x=theta)) + geom_histogram(bins=12) + theme_minimal() +
geom_vline(xintercept=1,linetype='solid',color='red',size=1) +
labs(title='Estimates of Theta',x='Theta',y='Count')
p2
source('multiplot.R')
png('q3_4c_R.png')
multiplot(p1, p3, p2, p4, cols=2)
dev.off()
avg_K     <- mean(Ks)
median_K  <- median(Ks)
avg_theta <- mean(thetas)
avg_bias  <- mean(thetas)-1
samp_var  <- sd(thetas)^2
avg_vhat  <- mean(SEs^2)
coverage  <- 1 - mean(df$ci_low > 1 | df$ci_high < 1)
