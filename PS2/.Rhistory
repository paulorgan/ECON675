###############################################################################
# Author: Paul R. Organ
# Purpose: ECON 675, PS1
# Last Update: Sept 24, 2018
###############################################################################
# Preliminaries
options(stringsAsFactors = F)
# packages
require(tidyverse) # data cleaning and manipulation
require(magrittr)  # syntax
require(xtable)    # regression table output
require(perm)      # permutation tests
require(boot)      # bootstrapping
require(ggplot2)   # plots
set.seed(22)
select = dplyr::select
setwd('C:/Users/prorgan/Box/Classes/Econ 675/Problem Sets/PS1')
###############################################################################
# read in data
df <- read_csv('LaLonde_1986.csv')
###############################################################################
# Question 2: Implementing Least-Squares Estimators
# add necessary variables
df %<>% mutate(educ2 = educ*educ, blackXearn74 = black * earn74)
# run regression
reg <- lm(earn78 ~ treat + black + age + educ + educ2 +
earn74 + blackXearn74 + u74 + u75, data = df)
# start table
q2 <- xtable(reg)
colnames(q2) <- c('coefficient', 'std_error', 't_stat', 'p_val')
# Z-value for 95%
z = qnorm(.025, lower.tail=F)
# add confidence interval
q2$conf_int <-
paste0('[',round(q2$coefficient-z*q2$std_error,2),', ',
round(q2$coefficient+z*q2$std_error,2),']')
# output table for Latex
xtable(q2)
###############################################################################
## Question 3: Analysis of Experiments
# 3.1) Neyman's Approach:
# 3.1a) Average Treatment Effect
N1 = sum(df$treat==1)
N0 = sum(df$treat==0)
sumY1 = sum(df$earn78[df$treat==1])
sumY0 = sum(df$earn78[df$treat==0])
Ybar1 = sumY1/N1
Ybar0 = sumY0/N0
ATE = Ybar1-Ybar0
# 3.1b) t-test
S1 = (1/(N1-1))*var(df$earn78[df$treat==1])
S0 = (1/(N0-1))*var(df$earn78[df$treat==0])
se <- sqrt(S1+S0)
Tstat = ATE / se
pval = 2*pnorm(-abs(Tstat))
CI_31b = paste0('[',round(ATE-z*sqrt(S1+S0),2),', '
,round(ATE+z*sqrt(S1+S0),2),']')
# Canned version for comparison
t.test(earn78 ~ treat, data = df)
###############################################################################
# 3.2) Fisher's Approach
# 3.2a) p-Value
# Fisher
fisher_1 <- permTS(earn78 ~ treat, data = df,
alternative = 'two.sided', method = 'exact.mc',
control = permControl(nmc=999,p.conf.level=.95))
fisher_1
# Kolgomorov-Smirnov
earn78_0 <- df$earn78[df$treat==0]
earn78_1 <- df$earn78[df$treat==1]
ks.test(earn78_0, earn78_1, alternative = 'two.sided', exact = T)
# 3.2b) Confidence Interval
# Imputation assuming ATE is constant
# (Generating Yi(1) and Yi(0) for each i, assuming ATE estimate is constant)
Y1_imp <- (df$treat==1) * df$earn78 + (df$treat==0) * (df$earn78 + ATE)
Y0_imp <- (df$treat==1) * (df$earn78 - ATE) + (df$treat==0) * df$earn78
# define statistic (difference in means)
boot_T <- function(data, ind) {
mean(Y1_imp[df$treat[ind]==1]) - mean(Y0_imp[df$treat[ind]==0])
}
# run bootstrap using defined statistic
boot_results <- boot(df, R = 999, statistic = boot_T,
sim = "permutation", stype = "i")
# construct 95% confidence interval
CI_32b = paste0('[', quantile(boot_results$t,0.025), ', ',
quantile(boot_results$t,0.975), ']')
boot.T <- function(x, ind) {
temp <- mean(Y1.imputed[data$treat[ind]==1]) - mean(Y0.imputed[data$treat[ind]==0])
return(temp)
}
treat.hat=ATE
# data imputation under the constant treatment assumption
Y1.imputed <- (df$treat==1) * df$earn78 + (df$treat==0) * (df$earn78 + treat.hat)
Y0.imputed <- (df$treat==1) * (df$earn78 -treat.hat) + (df$treat==0) * df$earn78
boot.result <- boot(data = df, R = 1999, statistic = boot.T, sim = "permutation", stype = "i")
boot.T <- function(x, ind) {
temp <- mean(Y1.imputed[df$treat[ind]==1]) - mean(Y0.imputed[df$treat[ind]==0])
return(temp)
}
boot.result <- boot(data = df, R = 1999, statistic = boot.T, sim = "permutation", stype = "i")
cat("95% CI for constant treatment effect", ":", round(quantile(boot.result$t, c(0.025, 0.975)), 3), "\n")
?runif
options(stringsAsFactors = F)
# packages
require(tidyverse) # data cleaning and manipulation
require(magrittr)  # syntax
require(ggplot2)   # plots
require(kedd)      # kernel estimation
require(ks)        # kernel estimation
require(car)       # heteroskedastic robust SEs
setwd('C:/Users/prorgan/Box/Classes/Econ 675/Problem Sets/PS2')
d <- 5
# testing
n <- 100
# X is a d by n matrix ~ U(-1,1)
X <- matrix(runif(n*d,-1,1), ncol=d)
# V ~ N(0,1)
V <- rnorm(n)
# Eps = .36...*(1+||X||^2)*V
E <- 0.3637899*(1+diag(X %*% t(X)))*V
# g_0(X) = exp(||X||^2)
G <- exp(diag(X %*% t(X)))
# T = ind(||x||+u >= 0)
t <- a
# T = ind(||x||+u >= 0)
t <- 7
# T = ind(||x||+u >= 0)
Tee <- sqrt(diag(X %*% t(X))) + U >= 0
U <- rnorm(n)
# T = ind(||x||+u >= 0)
Tee <- sqrt(diag(X %*% t(X))) + U >= 0
# T = ind(||x||+u >= 0) (times 1 to convert from Boolean to numeric)
Tee <- (sqrt(diag(X %*% t(X))) + U >= 0)*1
